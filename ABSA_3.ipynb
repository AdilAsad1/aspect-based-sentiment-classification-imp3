{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G7GLDR6oz28V"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcZrQhWC7WrM",
        "outputId": "a4fed458-ac36-4489-cc24-b4d4cad09d64"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the tweet to analyze\n",
        "tweet = \"Just tried the new Starbucks Unicorn Frappuccino and it's amazing! The colors are so fun and it tastes delicious! However, it's a bit too sweet for my taste.\"\n",
        "\n",
        "# Define the aspects to extract\n",
        "aspects = [\"taste\", \"color\", \"too sweet\"]"
      ],
      "metadata": {
        "id": "BJnKO0tfz48n"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Text preprocessing\n",
        "# Convert to lowercase\n",
        "tweet = tweet.lower()\n",
        "\n",
        "# Remove punctuation\n",
        "tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Tokenize\n",
        "tokens = word_tokenize(tweet)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "# Join tokens back into a string\n",
        "tweet = ' '.join(tokens)"
      ],
      "metadata": {
        "id": "d2qI12sQz5J5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Aspect sentiment extraction\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "sentences = sent_tokenize(tweet)\n",
        "aspect_sentiments = {}\n",
        "\n",
        "for aspect in aspects:\n",
        "  aspect_sentiments[aspect] = []\n",
        "  for sentence in sentences:\n",
        "    if aspect in sentence:\n",
        "      sentiment = sentiment_analyzer.polarity_scores(sentence)['compound']\n",
        "      aspect_sentiments[aspect].append(sentiment)"
      ],
      "metadata": {
        "id": "idU8qaAcz5aE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Aspect ranking and selection\n",
        "aspect_scores = {}\n",
        "for aspect, sentiments in aspect_sentiments.items():\n",
        "  if len(sentiments) > 0:\n",
        "    aspect_scores[aspect] = sum(sentiments) / len(sentiments)\n",
        "\n",
        "sorted_aspects = sorted(aspect_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "top_aspect = sorted_aspects[0][0]\n"
      ],
      "metadata": {
        "id": "Xfs_2izkz5lx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(aspect_scores[top_aspect])\n",
        "\n",
        "# Step 4: Aspect classification\n",
        "if aspect_scores[top_aspect] > 0:\n",
        "  print(f\"The {top_aspect} of the Starbucks Unicorn Frappuccino has a positive sentiment.\")\n",
        "else:\n",
        "  print(f\"The {top_aspect} of the Starbucks Unicorn Frappuccino has a negative sentiment.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4jkKBjk7Mdl",
        "outputId": "98f616af-5ae6-4d5d-ff14-38cb8e15222f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.93\n",
            "The taste of the Starbucks Unicorn Frappuccino has a positive sentiment.\n"
          ]
        }
      ]
    }
  ]
}